{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model with dropout on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.          -9.97997998  -9.95995996  -9.93993994  -9.91991992]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -2.0, 2.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def activation_function(x):\n",
    "    \"\"\"\n",
    "    Step function to respond with y = 1 or -1\n",
    "    Parameter:\n",
    "    x: An x (numeric) value that will have a corresponding y value of 1 or -1\n",
    "    \"\"\"\n",
    "    if x < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "rnge = np.linspace(-10.0, 10.0, num=1000)\n",
    "print(rnge[0:5])\n",
    "values = [activation_function(i) for i in rnge]\n",
    "plt.plot(rnge, values)\n",
    "plt.xticks(np.arange(-5, 5, 0.5))\n",
    "plt.axis([-5, 5, -2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perceptron(inp, weights):\n",
    "    output = activation_function(np.dot(inp, weights))\n",
    "    return output\n",
    "\n",
    "perceptron([1, 2, 3, 4, 5], [1, 1, 2, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233.479920</td>\n",
       "      <td>23.514130</td>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>231.324467</td>\n",
       "      <td>26.033830</td>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.906954</td>\n",
       "      <td>6.846577</td>\n",
       "      <td>mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230.276523</td>\n",
       "      <td>24.077800</td>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.360593</td>\n",
       "      <td>6.605983</td>\n",
       "      <td>mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>20.614362</td>\n",
       "      <td>6.575722</td>\n",
       "      <td>mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>22.249846</td>\n",
       "      <td>6.951267</td>\n",
       "      <td>mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>228.568162</td>\n",
       "      <td>27.146987</td>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>229.002922</td>\n",
       "      <td>23.526073</td>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>231.160957</td>\n",
       "      <td>25.548475</td>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         weight     height   type\n",
       "0    233.479920  23.514130    rat\n",
       "1    231.324467  26.033830    rat\n",
       "2     17.906954   6.846577  mouse\n",
       "3    230.276523  24.077800    rat\n",
       "4     20.360593   6.605983  mouse\n",
       "..          ...        ...    ...\n",
       "244   20.614362   6.575722  mouse\n",
       "245   22.249846   6.951267  mouse\n",
       "246  228.568162  27.146987    rat\n",
       "247  229.002922  23.526073    rat\n",
       "249  231.160957  25.548475    rat\n",
       "\n",
       "[245 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAeFElEQVR4nO3de3BcZ5nn8e8jWbblq7pt2ZFlS60E49yc+NJtYAwB4qkYmDAxmSVLWIbAZDGzCwPUzLpwmFnIsFtFZrNkqrZma2pCQZGZZRhSQzCBndmECmEpqAVbvsSOcUwglmzLju1EF99k6/bsH+e0IsuSpW51q/uc/n2qXJJP91G/J8f51dFznvc95u6IiEj0VJV6ACIikh8FuIhIRCnARUQiSgEuIhJRCnARkYiaMZ0ftnjxYk+lUtP5kSIikbd79+7X3L1+9PZpDfBUKkVra+t0fqSISOSZWftY21VCERGJKAW4iEhEKcBFRCJKAS4iElETBriZzTaznWb2gpkdNLO/DLcnzexHZvZy+DVR/OGKiEjWZLpQLgN3uvt5M6sBfmZm/wrcCzzn7o+Y2XZgO/D5Io5VRCQvO/Z28OgzhznR3cuyulq2bV7FlrWNpR7WlE14Be6B8+Ffa8I/DtwDPBFufwLYUpQRiohMwY69HTz01AE6untxoKO7l4eeOsCOvR2lHtqUTaoGbmbVZrYPOA38yN1/CSx195MA4dcl4+y71cxazaz1zJkzhRq3iMikPPrMYXr7B6/Y1ts/yKPPHC7RiApnUgHu7oPuvgZYDmwws1sn+wHu/ri7p909XV9/1UQiEZGiOtHdO+b2ju5eNj7y40hfiefUheLu3cBPgPcAp8ysASD8errgoxMRmaJldbXjvhb1cspkulDqzawu/L4W+F3gJeBp4IHwbQ8A3y/WIEVE8vXuG6/9m3+UyymT6UJpAJ4ws2qCwH/S3X9oZv8PeNLMHgSOAh8s4jhFRPLy/EsT33sbr8xS7iYMcHffD6wdY/vrwKZiDEpEpFAmE87XKrOUM83EFJFYW1hbc83Xa2uq2bZ51TSNprAU4CISa2bXfv0r966O7KQeBbiIxFr3xf5xX6ueKN3LnAJcRGLtWvXtQfd4txGKiETZts2rqK2pHvf1uLcRiohEVra+/egzh+kYpyMltm2EIiJRFixmtZ/e/qFx3xPVNkIFuIjE1o69Hfzpd/YxfnRHu41QAS4isfXoM4evGd6JOTV86f23qI1QRKTcTFTbnjNzRmTDGxTgIhJjE83CHO+mZlQowEUkti72DUz4npv/87+qD1xEpJzs2NtB36BP+L6L/UN87jv7WPvlZyMX5ApwEYmlXCfndF3sj9ysTAW4iMRSPpNzojYrUwEuIrGU7+ScKM3KVICLSCxN9Ci18URpVqYCXERiaTKPUhstarMyNRNTRGIp11JIY10t2zavitTEHgW4iMTSsrranCbq/Hz7nUUcTXGohCIisZRLDXxmdTSfzKMAF5FYyqUG3j+JCT/lSAEuIrGUS/kkmvGtABeRmMrlecXRLKAowEUkpjyHy2oHNj7y40hNowcFuIgIEJRcYrcWipmtMLPnzeyQmR00s8+G2x82sw4z2xf+eV/xhysiMjl1E6wFPpY4roUyAPyZu98EvBX4lJndHL721+6+JvzzL0UbpYhIjh7+/Vvy2i9Wa6G4+0l33xN+fw44BERnqpKIVKQtaxvzujlZNyf3K/dSyakGbmYpYC3wy3DTp81sv5l9w8wS4+yz1cxazaz1zJnc1yYQEclXPu2B5y8NRKYOPukAN7N5wHeBz7n7WeBvgRuANcBJ4Ktj7efuj7t72t3T9fX5rQ4mIjJd+oc8MnXwSQW4mdUQhPe33P0pAHc/5e6D7j4EfA3YULxhiohMn6g87HgyXSgGfB045O6PjdjeMOJtHwBeLPzwRESmX3Uus4BKaDKrEW4E/hA4YGb7wm1fAO43szUEZaY24JNFGaGIyDQbzGUWUAlNGODu/jPGnmmqtkERiaXGiDyVRzMxRURGiNJTeRTgIhJL+bQC1tXW8JV7V0fmqTx6Io+IxFKurYBzaqrY96W7ijSa4tAVuIjEUq5T4vsHPTITeLIU4CISS7lOiY/SBJ4sBbiIxM5f7DhA18X+nPeL0kJWoAAXkZjZsbeD//WLo3ntuywi7YNZCnARiZV8yyBRah/MUoCLSKzkUwYx4A/WN0amfTBLAS4isZJPGcSB51+K3nLXCnARiZV8yyBRu4EJCnARiZktaxv5yFubct4vajcwQQEuIjH0X7eszumhxga8+8boPXBGAS4isdTdO/k+cAe+9Yuj/MWOA8UbUBEowEUklnJ9KEM2xKM0nV4BLiKxlM9DGZz8+8hLQQEuIrGU70MZotSNogAXkVjatnkVtTXVOe8XpW4UBbiIxNKWtY185d7V49bCa2uqrnpWZNSm0+uBDiISW9mp8Q89dYDe/sHh7bU11Xzl3tVAUPM+0d3Lsrpatm1eFanp9ApwEYmdHXs7rgjmP1jfyPMvnRkzqKMU2KMpwEUkVnbs7bjiiruju5fv7u6I1LMuJ0s1cBGJlUefOXxFuQSgt38wUu2Bk6UAF5FYGa8NMErtgZOlEoqIxMqyulo6xgjrbHvg6Pp41G5cjmSex2ylfKXTaW9tbZ22zxORyjO6Bg5Xdp2Mfs0IZmA2lnGYm9lud0+P3j5hCcXMVpjZ82Z2yMwOmtlnw+1JM/uRmb0cfk0UY+AiIrnI9n831tViBMGcvYE5Vn08ewnb0d3LQ08diNRaKBNegZtZA9Dg7nvMbD6wG9gCfAzodPdHzGw7kHD3z1/rZ+kKXERKqWX7/2aimkNjXS0/337ntIxnsvK+Anf3k+6+J/z+HHAIaATuAZ4I3/YEQaiLiJStyUyTj9LNzpy6UMwsBawFfgksdfeTEIQ8sKTQgxMRKaTJrI8Sy7VQzGwe8F3gc+5+Nof9tppZq5m1njkTvYeGikh8jKyPA5FfC2VSXShmVgP8EHjG3R8Ltx0G3uXuJ8M6+U/c/ZpHrhq4iJSTqLQUjlcDn7AP3MwM+DpwKBveoaeBB4BHwq/fL9BYRUSmxZa1jdMW2O6O5fiUoIlMZiLPRuAPgQNmti/c9gWC4H7SzB4EjgIfLOjIREQiamjI+e2Z8+xs66S1rYtdbZ38zw+v4/YVdQX9nAkD3N1/xtWloqxNBR2NiEgE9Q0McaCjh9a2Tna1ddLa3kX3xeChyovnzSKTSlBdVdirb9BUehGRnJ291M+e9i5a27rY2dbJC8e6uTwwBMD1i+dy181LSaeSbEglaV40p+ClkywFuIjIBF7tuRRcWbd1squti5dePcuQQ3WVceuyBXzkrc1kUgnWNyepnz9r2salABcRGcE9rF8f6QoCu72TY53B5J7ammrWNdfxmU0ryaSSrFlRx9xZpYtRBbiIVLS+gSFePNHDriPB1fXu9k66huvXM0k3J/nY77SQSSW4qWEBNdXlswq3AlxEKsq5S/3sOdpNa1snO490sm9E/bpl8Vx+96alZFJJMi1JUkWsXxeCAlxEYu3U2Wz9OmjnO3QyqF9XGdyybCH/7i1h/TqVYMn82aUebk4U4CISG0H9+kJwdR2G9tHOi0BQv17bVMef3BnWr5vqmFfC+nUhRHv0IlLR+gaGOHiiZ7idb3d7F50X+gBYNHcm65sTfPRtzWRSSW5eVl7160JQgItIZJy/PBD2Xwc3HPce6+JSf1C/Ti2aw503LiGTSpBOJbl+8dyyrl8XggJcRMrW6bOX2BXWrlvbO/nViTfq1zcvW8D9G5rIpJKkmxMsWRCt+nUhKMBFpCy4O6+8dmG4na+1vZP214P69eyaKtauSPDpO1eSSSVY25SIfP26EPRfQERKon9wiIMnzoaBHawfkq1fJ+fOJN2c4CNvaSbTkuSWGNavC0EBLiLT4vzlAfYe7QpKIkc6r6hfNy+aw7tXBfXrTEtl1K8LQQEuIkVx+tyl4d7rXW1X168/lAnr16kESyuwfl0ICnARmTJ358hrF8KwDrpE2kbXr9/9JtKpJGub6pg/u6bEI44HBbiI5Kx/cIhfnTg7fHXd2tbF62H9OjGnhnQqyYffElxh37JsITNnqH5dDApwEZnQhcsD7D3aPRzYe49209s/CEBTcg7vXFUfrB+SSnJDverX00UBLiJXOXPu8vBkmdb2Tg6eOMvgkFNlcFPDAv5tZgXpVIJ0c5LrFqp+XSoKcJEK5+60vX7xina+I69dAGDWjCrWrKjjP77rhuH69QLVr8uGAlykwgwMDvGrk2fZeSSoXbe2d/La+aB+XTenhnRzkvs3rCCdSnKr6tdlTQEuEnMXLg+w79iV9euLfUH9ekWyljtW1gfPb2xJcP3ieVQV4eG7UhwKcJGYOXPuMrvb32jnezGsX5vBTdct4IPrl5MObziqfh1tCnCRCHN32l+/GK59HZREXhlRv759RR3/4Z03kE4lWNecUP06ZhTgIhEyMDjEoZPnhgN7V1sXr52/DGTr1wnuy6wgk0pya+MCZs2oLvGIpZgU4CJl7GLfAPuOdg8vqbrnaNdw/Xp5opZ3rFxMOpVgQyrJDfWqX1caBbhIGXnt/OWgMyS84Tiyfn3jdQv4N8P16wQNC2tLPVwpMQW4SIlk69fDD9xt7+SVM0H9embYf/3H77yedCrJuqYEC2tVv5YrTRjgZvYN4G7gtLvfGm57GPgEcCZ82xfc/V+KNUiROBgYHOKlV88F/ddhl8iZc0H9emFtWL9OryCTSnBr40LVr2VCk7kC/ybwN8Dfj9r+1+7+3ws+IpGY6O0bZO+xruElVfe0d3EhrF831tWy8YZFYf91kjepfi15mDDA3f2nZpYq/lBEou3185dpDR+4u7Oti4MdPQyE9etVS+dz77rlpFMJMqkky+pUv5apm0oN/NNm9lGgFfgzd+8a601mthXYCtDU1DSFjxMpH+7O0c6Lw5NldrV18tuR9evldWy943oy2fr1HNWvpfDM3Sd+U3AF/sMRNfClwGuAA/8FaHD3P5ro56TTaW9tbZ3KeEVKYnDIOXTy7Bs3HNs6OR3WrxfMnkE6fLLMhlSSWxsXMrtG9WspHDPb7e7p0dvzugJ391MjfvDXgB9OYWwiZae3b/Cq9UPOXx4Agvr1225YNLz+9colql9LaeQV4GbW4O4nw79+AHixcEMSmX6dF/qCqejtXew80smLo+rXW9YuC5/fmKRR9WspE5NpI/w28C5gsZkdB74EvMvM1hCUUNqATxZxjCIF5e4c6+wN174O2vl+c/o8ADOrq7h9xUI+ccf1ZFIJ1jclVb+WsjWZLpT7x9j89SKMRaQoBoecl149GzywIOwSOXU2qF/Pnz2DdHOCe9c1kkklWa36tUSIZmJK7FzqD+rX2Xa+Pe1dw/XrhoWzeUvLIjKpBJmWJG9eMl/1a4ksBbhEXteFvuH+611tnRzo6KF/MOiuWrV0PvesCerXmRbVryVeFOASKe7O8a7esDskCO2Xw/p1TbVx2/I6Hnx7WL9uTlA3Z2aJRyxSPApwKWuDQ87hV88Nt/O1tnXx6tlLAMyfNYP1qQRb1gb169uWq34tlUUBLmXlUv8gLxzrHm7n29Pexbmwfn3dgtlkWoKlVDOpJG9eOp9q1a+lginApaS6L/YNL6W668iV9es3L53H+9csGw7sxrpazBTYIlkKcJk27k5H95X161+furJ+/UdvbyHTnGR9c4LEXNWvRa5FAS5FMzjk/PrUuSsC+2TPG/Xrdc0J7lnTSLo5we0r6lS/FsmRAlwK5lL/IPuP9wzfcNzd3sW5S0H9eumCWcNrh2RSSVZdp/q1yFQpwCVv3Rf72N3eNfzA3QPHe+gbHAJg5ZJ53H3bG/Xr5QnVr0UKraIDfMfeDh595jAnuntZVlfLts2r2LK2sdTDKlvHuy4OL6Xa2tbF4VPngKB+vbpxIR/fmCKdCurXSdWvRYquIgN8x94OHn76IN29/cPbOrp7eeipAwAKcWBoyPn16XPB+iFh/fpEWL+eF9av776tgUxLktuX11E7U/VrkelWcQG+Y28HDz11gN7+wate6+0f5NFnDldkgF/qH+RAR0/wwN2wfn02rF8vmT+LTEuST4YPLbjxugWqX4uUgYoL8EefOTxmeGed6O6dxtGUTs/FfnYfDa6udx3pZP+I+vWblszj925rIN0cPHBX9WuR8lRxAT5RQMf1YbMd3b3Diz1l69fuMKPKWL18IR/bmCLdnCCdSqp+LRIRFRfgy+pq6RgnxGtrqtm2edU0j6jwhoacl0+fZ2dbUA5pbesaPua5M6tZ15zg91Y3kE4lWbNC9WuRqKq4AN+2edWYNfDEnBq+9P5bIln/vjwwyIHjPWFgBzccs/Xr+vmz2JBK8ol3tJBOJbnxuvnMqK4q8YhFpBAqLsCzAT1W++COvR1sfOTHZd9W2NPbz572ruEJMy8c76FvIKhf31A/l/eFV9cbUklWJFW/Fokrc/dp+7B0Ou2tra3T9nm5GKs7pbammq/cu7rkIX4iXD8k24M9sn59a+NCMqmgdp1uTrBo3qySjlVECs/Mdrt7evT2irsCz07e6ejupdqMQXca62q52DdwVVmlFG2F2fr1rrB+vWuM+vV7b20g05JgzYo65sysuFMoIqGK+r9/9FX2YPjbx3g3NaH4bYWXBwZ5saOHnUeC2nVrexc94QSjxfNmsaElwb9/RwsZ1a9FZJSKCvCJesDHUui2wp7efvYcDZ/feKSLfce7h+vX19fP5T23XEc6lWBDS5Km5BzVr0VkXBUV4LleTReirfBkT+/wVPSdR96oX1eH9euPvrU5qF+nEixW/VpEclBRAX6tHvDRGvPoQhkacn5z5vwVNxyPdwWfN2dmNeuawvp1KsGaJtWvRWRqKipBtm1exbZ/fmH4kV3jMeDn2++c8Of1DQxxoKNn+IZja3sX3RffqF9nUgk+vrGFDakkNzWofi0ihVVRAQ4wOEF4w/h177OXgv7r1rYudrZ18sKxbi5n69eL53LXzUuH+6+bF6l+LSLFNWGAm9k3gLuB0+5+a7gtCXwHSAFtwH3u3lW8YRbGw08fZGiC99RU23Dd+9WeS8NX1zvbunjp1bNv1K+XLeAjb20mk0qwvjlJ/XzVr0Vkek3mCvybwN8Afz9i23bgOXd/xMy2h3//fOGHV1gj1/8ez4yqKn766zN89UeHOdYZ1K9ra6pZ11zHZzetJN2cZG1THXNnVdwvLyJSZiZMIXf/qZmlRm2+B3hX+P0TwE+IQICP5zpep5dZ9DCP3v5BfnroOOkbGvjY77SQSSW4qWEBNapfi0iZyfcycqm7nwRw95NmtmS8N5rZVmArQFNTU54fN3XnLvUzb1Y15y8PsogezlPLZYJlU2dbH++oOkDGDpOpOkzKT2O3/x3ctr5k4xURmUjR6wDu/jjwOARroRT787JOnb003M6380gnL716liEHw2mw19lQ9RKZqsOkqw5Tb2ev/gE/+Bzcdt90DVdEJGf5BvgpM2sIr74bgNOFHFSu3J3fnrkwvDpfa1sXRzsvAkH9em1THX9y50oyqSSrvruJ+kttE//Q/gvFHbSIyBTlG+BPAw8Aj4Rfv1+wEU1C38AQB0/0hIEdzHLsCvuvF82dSTqV4KNvayaTSnLzslH168mEt4hIBEymjfDbBDcsF5vZceBLBMH9pJk9CBwFPljMQZ671M/eo91hO18n+451c6k/aAhMLZrDppuWkkklyKSStCyeO37/9f4nJ/+hppuWIlLeJtOFcv84L20q8FjG9Zc/+BX/vPs4VQa3LFvI/RuayITrhyyZP3vyP+i5L0/+ves/nvtARUSmUSSamR94W4p71ixjbVOCeVPpv+45Nvn3vvxscMWuG5kiUqYiEeCrly8szA+yKvCJ5mKGeo7BDz4TfK8QF5EyVFmF3smGd1Z/b25lFxGRaVRZAZ6PnuOlHoGIyJgqK8Br5ua+z8LlhR+HiEgBVE6A738ShiZezOoK1TNh0xeLMx4RkSmqnAB/7ssw2JfbPjPn6QamiJStygnwfGrZvWW/xLmIVLDKCfB8atmqf4tIGaucAN/0Raiqzm2flXcVZywiIgVQOQF+9BcwNJjbPi8/W5yxiIgUQOUE+O5v5r6PesBFpIxVToB7jlffALWJwo9DRKRAKifALcf6N0Df+dyWoBURmUaVE+DrP5b7PoN9WgtFRMpW5QT43Y/lt5/q4CJSpionwAEWrshjH/WCi0h5qqwAz6evW2uhiEiZqqwAz6evW2uhiEiZqqwAz+WRaiIiZa6yAjyfVkIRkTJVWQGe62SeqpnFGYeISAFUToA/8fu57zOU4/rhIiLTqDIC/Id/Ckf+b377/lWLZmOKSFmqjADPZyGrrN5O+P6nFOIiUnYqI8DzWchqJE2pF5EyNGMqO5tZG3AOGAQG3D1diEEVnFVPPcQ1pV5EykwhrsDf7e5ryja8Ib+FrEbTlHoRKTOVUUK5+zFIPzi1n6Ep9SJSZqYa4A48a2a7zWzrWG8ws61m1mpmrWfOnJnix03B3Y/BvV/Lf39NqReRMjPVAN/o7uuA9wKfMrM7Rr/B3R9397S7p+vr66f4cQWQz2zMfFYxFBEpsikFuLufCL+eBr4HbCjEoIpi/5PwvT/O/WZmTa3KJyJSlvIOcDOba2bzs98DdwEvFmpgBbX/SfjBZ3IP79okvP9/qHwiImVpKm2ES4HvmVn25/yju/+fgoyq0J77MvT35r7fzLkKbxEpW3kHuLu/AtxewLEUT7493Or9FpEyVhlthPn2cKv3W0TKWGUE+KYvBjcjc6GblyJS5iojwG+7L7gZmW0HtEkc9owcA19EZJpNaS2USMnejPzBZyZ3Q7O3M3jvyH1FRMpIZVyBZ+XajdLfq1UIRaRsVVaA59NVok4UESlTlRXg+XSVqBNFRMpUZQX4pi9C9TgPKm5559WdKupEEZEyVlkBftt9MHPe2K91vjKiU8WCr5pGLyJlrHK6ULJ6u8be3nMsCGsFtohERGVdgcM1atqmBxeLSKRUXoBv+iJgY7zgahkUkUipvAC/7T6CBwmNQS2DIhIhlRfgMP4TdtQyKCIRUpkBvvIuriqjqGVQRCKm8gJ8/5Pwwj9yZRnF4PYPqwNFRCKl8gJ8zPVQHF5+tiTDERHJV+UF+Hg3KnUDU0QipvICfLwblbqBKSIRU3kBPtbTeXQDU0QiqPIC/Iqn82jNExGJrspbCwW05omIxELlXYGLiMSEAlxEJKIU4CIiEaUAFxGJKAW4iEhEmfs4S6sW48PMzgDtee6+GHitgMMpdzre+KqkYwUdbyE0u3v96I3TGuBTYWat7p4u9Timi443virpWEHHW0wqoYiIRJQCXEQkoqIU4I+XegDTTMcbX5V0rKDjLZrI1MBFRORKUboCFxGRERTgIiIRFYkAN7P3mNlhM/uNmW0v9XgKzczazOyAme0zs9ZwW9LMfmRmL4dfE6UeZ77M7BtmdtrMXhyxbdzjM7OHwnN92Mw2l2bU+RvneB82s47wHO8zs/eNeC2yx2tmK8zseTM7ZGYHzeyz4fZYnt9rHG9pzq+7l/UfoBr4LXA9MBN4Abi51OMq8DG2AYtHbftvwPbw++3AX5V6nFM4vjuAdcCLEx0fcHN4jmcBLeG5ry71MRTgeB8G/tMY74308QINwLrw+/nAr8NjiuX5vcbxluT8RuEKfAPwG3d/xd37gH8C7inxmKbDPcAT4fdPAFtKOJYpcfefAp2jNo93fPcA/+Tul939CPAbgn8DkTHO8Y4n0sfr7ifdfU/4/TngENBITM/vNY53PEU93igEeCNwbMTfj3Pt/2BR5MCzZrbbzLaG25a6+0kI/tEAS0o2uuIY7/jifL4/bWb7wxJLtqQQm+M1sxSwFvglFXB+Rx0vlOD8RiHAbYxtcet93Oju64D3Ap8ysztKPaASiuv5/lvgBmANcBL4arg9FsdrZvOA7wKfc/ez13rrGNvicLwlOb9RCPDjwIoRf18OnCjRWIrC3U+EX08D3yP4FeuUmTUAhF9Pl26ERTHe8cXyfLv7KXcfdPch4Gu88Wt05I/XzGoIwuxb7v5UuDm253es4y3V+Y1CgO8CVppZi5nNBD4EPF3iMRWMmc01s/nZ74G7gBcJjvGB8G0PAN8vzQiLZrzjexr4kJnNMrMWYCWwswTjK6hsmIU+QHCOIeLHa2YGfB045O6PjXgplud3vOMt2fkt9V3dSd75fR/B3d7fAn9e6vEU+NiuJ7hL/QJwMHt8wCLgOeDl8Guy1GOdwjF+m+DXyn6CK5IHr3V8wJ+H5/ow8N5Sj79Ax/sPwAFgf/g/dUMcjhd4O0FJYD+wL/zzvrie32scb0nOr6bSi4hEVBRKKCIiMgYFuIhIRCnARUQiSgEuIhJRCnARkYhSgIuIRJQCXEQkov4/GsmfFBHpZdUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rodents_data = pd.read_csv('../data/rodents.csv', delimiter=';', dtype={'weight': float, 'height': float})\n",
    "rodents_data = rodents_data.dropna()\n",
    "for label in rodents_data.type.unique():\n",
    "    data = rodents_data[rodents_data['type'] == label]\n",
    "    plt.scatter(data['weight'], data['height'])\n",
    "    \n",
    "x = np.linspace(0,rodents_data.weight.max() + 20,10)\n",
    "y = 0.04*x+9.2\n",
    "plt.plot(x,y)\n",
    "\n",
    "\n",
    "rodents_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model1():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model2():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_model3():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 1.9113 - accuracy: 0.3113 - val_loss: 1.4278 - val_accuracy: 0.4954\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 1.3655 - accuracy: 0.5112 - val_loss: 1.2569 - val_accuracy: 0.5524\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.1642 - accuracy: 0.5887 - val_loss: 1.1074 - val_accuracy: 0.6104\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.0358 - accuracy: 0.6336 - val_loss: 1.0618 - val_accuracy: 0.6221\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.9363 - accuracy: 0.6710 - val_loss: 0.9985 - val_accuracy: 0.6487\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.8470 - accuracy: 0.7073 - val_loss: 0.9648 - val_accuracy: 0.6638\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7842 - accuracy: 0.7256 - val_loss: 0.9526 - val_accuracy: 0.6730\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.7039 - accuracy: 0.7534 - val_loss: 0.9426 - val_accuracy: 0.6775\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.6444 - accuracy: 0.7794 - val_loss: 0.9524 - val_accuracy: 0.6750\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5759 - accuracy: 0.8018 - val_loss: 0.9636 - val_accuracy: 0.6768\n",
      "> 67.680\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model1()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 1.8644 - accuracy: 0.3210 - val_loss: 1.3413 - val_accuracy: 0.5132\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2980 - accuracy: 0.5378 - val_loss: 1.1498 - val_accuracy: 0.5908\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 1.0823 - accuracy: 0.6197 - val_loss: 1.0548 - val_accuracy: 0.6262\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9460 - accuracy: 0.6707 - val_loss: 0.9633 - val_accuracy: 0.6657\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.8464 - accuracy: 0.7037 - val_loss: 0.9374 - val_accuracy: 0.6755\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.7575 - accuracy: 0.7384 - val_loss: 0.9417 - val_accuracy: 0.6782\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.6870 - accuracy: 0.7600 - val_loss: 0.8803 - val_accuracy: 0.6976\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.6035 - accuracy: 0.7931 - val_loss: 0.8804 - val_accuracy: 0.7033\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5272 - accuracy: 0.8178 - val_loss: 0.8914 - val_accuracy: 0.7039\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.4645 - accuracy: 0.8394 - val_loss: 0.9117 - val_accuracy: 0.7114\n",
      "> 71.140\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model2()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 1.9447 - accuracy: 0.2933 - val_loss: 1.3731 - val_accuracy: 0.5091\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 1.3160 - accuracy: 0.5323 - val_loss: 1.1365 - val_accuracy: 0.5988\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 1.0768 - accuracy: 0.6197 - val_loss: 1.0717 - val_accuracy: 0.6172\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 73s 47ms/step - loss: 0.9344 - accuracy: 0.6724 - val_loss: 0.9497 - val_accuracy: 0.6679\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 0.8169 - accuracy: 0.7158 - val_loss: 0.8821 - val_accuracy: 0.6974\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 78s 50ms/step - loss: 0.7169 - accuracy: 0.7517 - val_loss: 0.8669 - val_accuracy: 0.7001\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 77s 49ms/step - loss: 0.6284 - accuracy: 0.7814 - val_loss: 0.8871 - val_accuracy: 0.7019\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 74s 48ms/step - loss: 0.5536 - accuracy: 0.8085 - val_loss: 0.8125 - val_accuracy: 0.7256\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.4830 - accuracy: 0.8342 - val_loss: 0.8557 - val_accuracy: 0.7249\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.4201 - accuracy: 0.8556 - val_loss: 0.9816 - val_accuracy: 0.6903\n",
      "> 69.030\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model3()\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "781/781 [==============================] - 92s 116ms/step - loss: 2.4929 - accuracy: 0.2453 - val_loss: 1.4496 - val_accuracy: 0.4752\n",
      "Epoch 2/400\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 1.6660 - accuracy: 0.3926 - val_loss: 1.3753 - val_accuracy: 0.5008\n",
      "Epoch 3/400\n",
      "781/781 [==============================] - 92s 117ms/step - loss: 1.5090 - accuracy: 0.4493 - val_loss: 1.3718 - val_accuracy: 0.5058\n",
      "Epoch 4/400\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 1.4223 - accuracy: 0.4860 - val_loss: 1.3494 - val_accuracy: 0.4998\n",
      "Epoch 5/400\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 1.3509 - accuracy: 0.5115 - val_loss: 1.2384 - val_accuracy: 0.5554\n",
      "Epoch 6/400\n",
      "781/781 [==============================] - 84s 107ms/step - loss: 1.2988 - accuracy: 0.5309 - val_loss: 1.2739 - val_accuracy: 0.5405\n",
      "Epoch 7/400\n",
      "781/781 [==============================] - 97s 124ms/step - loss: 1.2465 - accuracy: 0.5519 - val_loss: 1.1591 - val_accuracy: 0.5870\n",
      "Epoch 8/400\n",
      "781/781 [==============================] - 97s 124ms/step - loss: 1.2079 - accuracy: 0.5622 - val_loss: 1.0383 - val_accuracy: 0.6282\n",
      "Epoch 9/400\n",
      "781/781 [==============================] - 95s 122ms/step - loss: 1.1706 - accuracy: 0.5799 - val_loss: 1.1183 - val_accuracy: 0.5938\n",
      "Epoch 10/400\n",
      "781/781 [==============================] - 98s 125ms/step - loss: 1.1445 - accuracy: 0.5905 - val_loss: 1.0691 - val_accuracy: 0.6193\n",
      "Epoch 11/400\n",
      "781/781 [==============================] - 98s 126ms/step - loss: 1.1072 - accuracy: 0.6029 - val_loss: 1.0295 - val_accuracy: 0.6365\n",
      "Epoch 12/400\n",
      "781/781 [==============================] - 97s 124ms/step - loss: 1.0801 - accuracy: 0.6145 - val_loss: 0.9922 - val_accuracy: 0.6454\n",
      "Epoch 13/400\n",
      "781/781 [==============================] - 99s 127ms/step - loss: 1.0465 - accuracy: 0.6322 - val_loss: 1.3337 - val_accuracy: 0.5398\n",
      "Epoch 14/400\n",
      "781/781 [==============================] - 98s 125ms/step - loss: 1.0341 - accuracy: 0.6334 - val_loss: 0.9489 - val_accuracy: 0.6626\n",
      "Epoch 15/400\n",
      "781/781 [==============================] - 99s 127ms/step - loss: 1.0127 - accuracy: 0.6385 - val_loss: 1.0594 - val_accuracy: 0.6277\n",
      "Epoch 16/400\n",
      "781/781 [==============================] - 100s 128ms/step - loss: 0.9898 - accuracy: 0.6473 - val_loss: 1.0006 - val_accuracy: 0.6412\n",
      "Epoch 17/400\n",
      "781/781 [==============================] - 98s 126ms/step - loss: 0.9696 - accuracy: 0.6584 - val_loss: 0.8880 - val_accuracy: 0.6845\n",
      "Epoch 18/400\n",
      "781/781 [==============================] - 101s 129ms/step - loss: 0.9481 - accuracy: 0.6646 - val_loss: 0.8829 - val_accuracy: 0.6869\n",
      "Epoch 19/400\n",
      "781/781 [==============================] - 100s 129ms/step - loss: 0.9465 - accuracy: 0.6643 - val_loss: 0.8846 - val_accuracy: 0.6878\n",
      "Epoch 20/400\n",
      "781/781 [==============================] - 99s 127ms/step - loss: 0.9307 - accuracy: 0.6734 - val_loss: 0.8894 - val_accuracy: 0.6875\n",
      "Epoch 21/400\n",
      "781/781 [==============================] - 102s 130ms/step - loss: 0.9149 - accuracy: 0.6775 - val_loss: 0.9168 - val_accuracy: 0.6732\n",
      "Epoch 22/400\n",
      "781/781 [==============================] - 98s 126ms/step - loss: 0.8972 - accuracy: 0.6842 - val_loss: 0.8335 - val_accuracy: 0.7033\n",
      "Epoch 23/400\n",
      "781/781 [==============================] - 100s 128ms/step - loss: 0.8964 - accuracy: 0.6867 - val_loss: 0.9200 - val_accuracy: 0.6732\n",
      "Epoch 24/400\n",
      "781/781 [==============================] - 107s 137ms/step - loss: 0.8806 - accuracy: 0.6895 - val_loss: 0.8197 - val_accuracy: 0.7109\n",
      "Epoch 25/400\n",
      "781/781 [==============================] - 101s 130ms/step - loss: 0.8813 - accuracy: 0.6885 - val_loss: 0.8696 - val_accuracy: 0.6948\n",
      "Epoch 26/400\n",
      "781/781 [==============================] - 107s 137ms/step - loss: 0.8594 - accuracy: 0.6973 - val_loss: 0.8369 - val_accuracy: 0.7038\n",
      "Epoch 27/400\n",
      "781/781 [==============================] - 101s 130ms/step - loss: 0.8602 - accuracy: 0.6973 - val_loss: 0.8058 - val_accuracy: 0.7154\n",
      "Epoch 28/400\n",
      "781/781 [==============================] - 102s 130ms/step - loss: 0.8349 - accuracy: 0.7067 - val_loss: 0.7834 - val_accuracy: 0.7209\n",
      "Epoch 29/400\n",
      "781/781 [==============================] - 85s 109ms/step - loss: 0.8320 - accuracy: 0.7092 - val_loss: 0.8064 - val_accuracy: 0.7166\n",
      "Epoch 30/400\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 0.8238 - accuracy: 0.7125 - val_loss: 0.8068 - val_accuracy: 0.7168\n",
      "Epoch 31/400\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 0.8074 - accuracy: 0.7191 - val_loss: 0.7973 - val_accuracy: 0.7183\n",
      "Epoch 32/400\n",
      "781/781 [==============================] - 85s 109ms/step - loss: 0.8104 - accuracy: 0.7146 - val_loss: 0.7581 - val_accuracy: 0.7312\n",
      "Epoch 33/400\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.7931 - accuracy: 0.7212 - val_loss: 0.7567 - val_accuracy: 0.7324\n",
      "Epoch 34/400\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 0.7863 - accuracy: 0.7230 - val_loss: 0.7884 - val_accuracy: 0.7203\n",
      "Epoch 35/400\n",
      "781/781 [==============================] - 92s 117ms/step - loss: 0.7806 - accuracy: 0.7241 - val_loss: 0.7910 - val_accuracy: 0.7206\n",
      "Epoch 36/400\n",
      "781/781 [==============================] - 102s 131ms/step - loss: 0.7698 - accuracy: 0.7333 - val_loss: 0.7950 - val_accuracy: 0.7205\n",
      "Epoch 37/400\n",
      "781/781 [==============================] - 102s 131ms/step - loss: 0.7750 - accuracy: 0.7301 - val_loss: 0.8205 - val_accuracy: 0.7113\n",
      "Epoch 38/400\n",
      "781/781 [==============================] - 106s 135ms/step - loss: 0.7600 - accuracy: 0.7343 - val_loss: 0.7118 - val_accuracy: 0.7493\n",
      "Epoch 39/400\n",
      "781/781 [==============================] - 104s 133ms/step - loss: 0.7536 - accuracy: 0.7365 - val_loss: 0.7198 - val_accuracy: 0.7441\n",
      "Epoch 40/400\n",
      "781/781 [==============================] - 108s 138ms/step - loss: 0.7588 - accuracy: 0.7339 - val_loss: 0.6937 - val_accuracy: 0.7577\n",
      "Epoch 41/400\n",
      "781/781 [==============================] - 97s 125ms/step - loss: 0.7408 - accuracy: 0.7415 - val_loss: 0.7025 - val_accuracy: 0.7565\n",
      "Epoch 42/400\n",
      "781/781 [==============================] - 96s 123ms/step - loss: 0.7361 - accuracy: 0.7442 - val_loss: 0.7357 - val_accuracy: 0.7453\n",
      "Epoch 43/400\n",
      "781/781 [==============================] - 93s 119ms/step - loss: 0.7367 - accuracy: 0.7457 - val_loss: 0.7019 - val_accuracy: 0.7548\n",
      "Epoch 44/400\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.7332 - accuracy: 0.7427 - val_loss: 0.6804 - val_accuracy: 0.7610\n",
      "Epoch 45/400\n",
      "781/781 [==============================] - 101s 130ms/step - loss: 0.7251 - accuracy: 0.7473 - val_loss: 0.6804 - val_accuracy: 0.7648\n",
      "Epoch 46/400\n",
      "781/781 [==============================] - 105s 134ms/step - loss: 0.7241 - accuracy: 0.7485 - val_loss: 0.6915 - val_accuracy: 0.7597\n",
      "Epoch 47/400\n",
      "781/781 [==============================] - 92s 117ms/step - loss: 0.7111 - accuracy: 0.7542 - val_loss: 0.7078 - val_accuracy: 0.7577\n",
      "Epoch 48/400\n",
      "781/781 [==============================] - 93s 119ms/step - loss: 0.6988 - accuracy: 0.7536 - val_loss: 0.6422 - val_accuracy: 0.7779\n",
      "Epoch 49/400\n",
      "781/781 [==============================] - 99s 126ms/step - loss: 0.7005 - accuracy: 0.7579 - val_loss: 0.7151 - val_accuracy: 0.7539\n",
      "Epoch 50/400\n",
      "781/781 [==============================] - 95s 122ms/step - loss: 0.6975 - accuracy: 0.7573 - val_loss: 0.6457 - val_accuracy: 0.7756\n",
      "Epoch 51/400\n",
      "781/781 [==============================] - 88s 113ms/step - loss: 0.6833 - accuracy: 0.7637 - val_loss: 0.6836 - val_accuracy: 0.7669\n",
      "Epoch 52/400\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 0.6901 - accuracy: 0.7596 - val_loss: 0.7296 - val_accuracy: 0.7517\n",
      "Epoch 53/400\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 0.6842 - accuracy: 0.7642 - val_loss: 0.6338 - val_accuracy: 0.7811\n",
      "Epoch 54/400\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6835 - accuracy: 0.7633 - val_loss: 0.6388 - val_accuracy: 0.7794\n",
      "Epoch 55/400\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 0.6710 - accuracy: 0.7668 - val_loss: 0.6445 - val_accuracy: 0.7794\n",
      "Epoch 56/400\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 0.6623 - accuracy: 0.7702 - val_loss: 0.6764 - val_accuracy: 0.7668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/400\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 0.6756 - accuracy: 0.7655 - val_loss: 0.5910 - val_accuracy: 0.7940\n",
      "Epoch 58/400\n",
      "781/781 [==============================] - 87s 111ms/step - loss: 0.6681 - accuracy: 0.7682 - val_loss: 0.5941 - val_accuracy: 0.7968\n",
      "Epoch 59/400\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 0.6432 - accuracy: 0.7817 - val_loss: 0.5745 - val_accuracy: 0.8035\n",
      "Epoch 60/400\n",
      "781/781 [==============================] - 86s 111ms/step - loss: 0.6474 - accuracy: 0.7783 - val_loss: 0.6129 - val_accuracy: 0.7883\n",
      "Epoch 61/400\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 0.6446 - accuracy: 0.7786 - val_loss: 0.5682 - val_accuracy: 0.8048\n",
      "Epoch 62/400\n",
      "781/781 [==============================] - 85s 109ms/step - loss: 0.6390 - accuracy: 0.7771 - val_loss: 0.6313 - val_accuracy: 0.7851\n",
      "Epoch 63/400\n",
      "781/781 [==============================] - 87s 112ms/step - loss: 0.6418 - accuracy: 0.7759 - val_loss: 0.6389 - val_accuracy: 0.7809\n",
      "Epoch 64/400\n",
      "781/781 [==============================] - 88s 113ms/step - loss: 0.6391 - accuracy: 0.7782 - val_loss: 0.7538 - val_accuracy: 0.7462\n",
      "Epoch 65/400\n",
      "781/781 [==============================] - 85s 109ms/step - loss: 0.6291 - accuracy: 0.7831 - val_loss: 0.6389 - val_accuracy: 0.7819\n",
      "Epoch 66/400\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 0.6179 - accuracy: 0.7852 - val_loss: 0.5894 - val_accuracy: 0.7979\n",
      "Epoch 67/400\n",
      "781/781 [==============================] - 86s 110ms/step - loss: 0.6229 - accuracy: 0.7848 - val_loss: 0.5755 - val_accuracy: 0.8014\n",
      "Epoch 68/400\n",
      "450/781 [================>.............] - ETA: 35s - loss: 0.6145 - accuracy: 0.7890"
     ]
    }
   ],
   "source": [
    "# baseline model with dropout and data augmentation on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import h5py\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\t# prepare iterator\n",
    "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\t# fit model\n",
    "\tsteps = int(trainX.shape[0] / 64)\n",
    "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=400, validation_data=(testX, testY), verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\tmodel.save('final_model.h5')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the deep model on the test dataset\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# evaluate model on test dataset\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
